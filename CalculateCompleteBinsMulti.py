from ParseBam import BamFileReadParser
import sys
import os
import logging
from multiprocessing import Pool
import numpy as np


def calculate_bin_coverage(bin):
    """
    Take a single bin, return a matrix
    :param bin: Bin should be passed as "Chr19_4343343"
    :return: pd.DataFrame with rows containing NaNs dropped
    """

    # Get reads from bam file
    parser = BamFileReadParser(input_bam_file, 20)
    # Split bin into parts
    chromosome, bin_location = bin.split("_")
    bin_location = int(bin_location)

    try:
        reads = parser.parse_reads(chromosome, bin_location-bin_size, bin_location)
        matrix = parser.create_matrix(reads)

    except ValueError:
        # No reads are within this window, do nothing
        logging.info("No reads found for bin {}".format(bin))
        return None

    # convert to data_frame of 1s and 0s, drop rows with NaN
    logging.debug("made it past try block")
    matrix = matrix.dropna()
    logging.debug(bin, matrix)

    return matrix

def get_chromosome_lengths():
    """
    Get dictionary containing lengths of the chromosomes. Uses bam file for reference
    :return: Dictionary of chromosome lengths, ex: {"chrX": 222222}
    """
    parser = BamFileReadParser(input_bam_file, 20)
    return dict(zip(parser.OpenBamFile.references, parser.OpenBamFile.lengths))

def remove_scaffolds(chromosome_len_dict):
    """
    Return a dict containing only the standard chromosomes starting with "chr"
    :param chromosome_len_dict: A dict generated by get_chromosome_lenghts()
    :return: a dict containing only chromosomes starting with "chr"
    """
    new_dict = dict(chromosome_len_dict)
    for key in chromosome_len_dict.keys():
        if not key.startswith("chr"):
            new_dict.pop(key)

    return new_dict

def generate_bins_list(chromosome_len_dict: dict):
    """
    Get a list of all bins according to desired bin size for all chromosomes in the passed dict
    :param chromosome_len_dict: A dict of chromosome length sizes from get_chromosome_lenghts, cleaned up by remove_scaffolds() if desired
    :return: list of all bins
    """
    all_bins = []
    for key, value in chromosome_len_dict.items():
        print(key)
        bins = list(np.arange(bin_size, value + bin_size, bin_size))
        bins = ["_".join([key, str(x)]) for x in bins]
        all_bins.extend(bins)

    return all_bins

# def analyze_bins(self):
#     # Get and clean dict of chromosome lenghts, convert to list of bins
#     chromosome_lenghts = self.get_chromosome_lengths()
#     chromosome_lenghts = self.remove_scaffolds(chromosome_lenghts)
#     bins_to_analyze = self.generate_bins_list(chromosome_lenghts)
#
#     # Set up for multiprocessing
#     logging.info("Beginning analysis of bins using {} processors".format(self.number_of_processors))
#     pool = Pool(processes=self.number_of_processors)
#     results = pool.map(self.calculate_bin_coverage, bins_to_analyze)
#     print("After results line")
#     logging.info("Analysis complete")
#
#     # Write to output file
#     output_file = os.path.join(self.output_directory, "CalculateCompleteBins_{}.csv".format(os.path.basename(self.input_bam_file)))
#
#     with open(output_file, "w") as out:
#         for result in results:
#             out.write(result[0] + ",")
#             out.write(str(result[1].shape[0]) + ",")
#             out.write(str(result[1].shape[1]) + "\n")
#
#     logging.info("Full read coverage anaysis complete!")


if __name__ == "__main__":

    # Input params
    # todo add these as command line args using argparse
    input_bam_file = sys.argv[1]
    num_of_processors = int(sys.argv[2])
    if not num_of_processors:
        num_of_processors = 1

    log_file = "CalculateCompleteBins.{}.log".format(os.path.basename(input_bam_file))
    BASE_DIR = os.path.dirname(input_bam_file)

    logging.basicConfig(filename=os.path.join(BASE_DIR, log_file), level=logging.DEBUG)


    ###############################

    bin_size = 100

    chromosome_lengths = get_chromosome_lengths()
    chromosome_lengths = remove_scaffolds(chromosome_lengths)
    bins_to_analyze = generate_bins_list(chromosome_lengths)

    # Set up for multiprocessing
    logging.info("Beginning analysis of bins using {} processors".format(num_of_processors))
    pool = Pool(processes=num_of_processors)
    results = pool.map(calculate_bin_coverage, bins_to_analyze)
    print("After results line")
    logging.info("Analysis complete")

    # Write to output file
    output_file = os.path.join(BASE_DIR,
                               "CalculateCompleteBins_{}.csv".format(os.path.basename(input_bam_file)))

    with open(output_file, "w") as out:
        for result in results:
            out.write(result[0] + ",")
            out.write(str(result[1].shape[0]) + ",")
            out.write(str(result[1].shape[1]) + "\n")

    logging.info("Full read coverage anaysis complete!")

    ###################################

