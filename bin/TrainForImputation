#!/usr/bin/env python3

import argparse
import pandas as pd
import numpy as np
from tqdm import tqdm
import time
import os
from multiprocessing import Pool
from MixtureAnalysis.ConnectToCpGNet import TrainWithCpGNet
from MixtureAnalysis.ParseBam import BamFileReadParser


class TrainForImputation:

    def __init__(self, cpg_density: int, bam_file: str, mbias_read1_5=None, mbias_read1_3=None, mbias_read2_5= None, mbias_read2_3=None):
        self.cpg_density = cpg_density
        self.bam_file = bam_file
        self.mbias_read1_5 = mbias_read1_5
        self.mbias_read1_3 = mbias_read1_3
        self.mbias_read2_5 = mbias_read2_5
        self.mbias_read2_3 = mbias_read2_3



    def extract_matrices(self, coverage_data_frame: pd.DataFrame):

        def track_progress(job, update_interval=30):
            while job._number_left > 0:
                print("Tasks remaining = {0}".format(job._number_left * job._chunksize), flush=True)
                time.sleep(update_interval)

        subset = coverage_data_frame[coverage_data_frame['cpgs'] == self.cpg_density]
        bins_of_interest = subset['bin'].unique()

        pool = Pool(processes=processes)
        matrices = pool.map_async(self.multiprocess_extract, bins_of_interest)

        track_progress(matrices)
        matrices = matrices.get()

        clean_matrices = []
        for matrix in matrices:
            if matrix.shape[1] == self.cpg_density:
                clean_matrices.append(matrix)

        return np.array(clean_matrices)


    def multiprocess_extract(self, one_bin: str):
        read_parser = BamFileReadParser(self.bam_file, 20, read1_5=self.mbias_read1_5, read1_3=self.mbias_read1_3, read2_5=self.mbias_read2_5, read2_3=self.mbias_read2_3)
        chrom, loc = one_bin.split("_")
        loc = int(loc)
        reads = read_parser.parse_reads(chrom, loc-100, loc)
        matrix = read_parser.create_matrix(reads)
        matrix = matrix.dropna(how="all")
        matrix = matrix.fillna(-1)
        matrix = np.array(matrix)

        return matrix


    def train_model(self, output_folder: str, matrices: iter):
        trainer = TrainWithCpGNet(cpg_density=self.cpg_density, save_path=output_folder)
        model = trainer.train_model(matrices)

        return model


if __name__ == "__main__":

    # Input params
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument("-a", "--input_bam_file",
                            help="Input bam file, coordinate sorted with index present", default=None)
    arg_parser.add_argument("-c", "--coverage", help="output file from CalculateCompleteBins", default=None)
    arg_parser.add_argument("-o", "--output", help="folder to save generated model files", default=None)
    arg_parser.add_argument("-n", help="number of cpu cores to use")
    arg_parser.add_argument("--read1_5", help="integer, read1 5' m-bias ignore bp, default=0", default=0)
    arg_parser.add_argument("--read1_3", help="integer, read1 3' m-bias ignore bp, default=0", default=0)
    arg_parser.add_argument("--read2_5", help="integer, read2 5' m-bias ignore bp, default=0", default=0)
    arg_parser.add_argument("--read2_3", help="integer, read2 3' m-bias ignore bp, default=0", default=0)

    # Extract arguments from command line and set as correct types
    args = arg_parser.parse_args()

    # Get the mbias inputs and adjust to work correctly, 0s should be converted to None
    mbias_read1_5 = int(args.read1_5)
    mbias_read1_3 = int(args.read1_3)
    mbias_read2_5 = int(args.read2_5)
    mbias_read2_3 = int(args.read2_3)
    processes = int(args.n)
    
    # Set output dir
    if not args.output:
        output_folder = os.path.dirname(args.input_bam_file)
    else:
        output_folder = args.output

    try:
        os.mkdir(output_folder)
    except FileExistsError:
        print("Output folder already exists... no need to create it...")

    # Read in coverage file
    coverage_data = pd.read_csv(args.coverage, header=None)
    coverage_data.columns = ['bin', 'reads', 'cpgs']

    # Train models
    for i in range(2,7):
        print("Starting training cpg density: {}".format(i))
        trainer = TrainForImputation(i, args.input_bam_file, mbias_read1_5, mbias_read1_3, mbias_read2_5, mbias_read2_3)
        matrices = trainer.extract_matrices(coverage_data)
        np.save("/home/anthony/Documents/DATA/2cpg_matrices.npy", matrices)
        model = trainer.train_model(output_folder, matrices)







    


